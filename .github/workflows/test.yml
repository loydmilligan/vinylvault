name: VinylVault Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, "3.10", "3.11"]

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt', '**/test-requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r test-requirements.txt

    - name: Run unit tests
      run: |
        python -m pytest tests/unit -v --tb=short --junit-xml=test-results/unit-results.xml --cov=. --cov-report=xml

    - name: Run integration tests
      run: |
        python -m pytest tests/integration -v --tb=short --junit-xml=test-results/integration-results.xml

    - name: Run API tests
      run: |
        python -m pytest tests/unit/test_api_endpoints.py -v --tb=short --junit-xml=test-results/api-results.xml

    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}
        path: test-results/

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.python-version == '3.9'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  docker-test:
    runs-on: ubuntu-latest
    needs: test

    steps:
    - uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Build Docker image
      run: |
        docker build -t vinylvault:test .

    - name: Run Docker tests
      run: |
        mkdir -p test-results htmlcov
        docker run --rm \
          -v $(pwd)/test-results:/app/test-results \
          -v $(pwd)/htmlcov:/app/htmlcov \
          vinylvault:test \
          python3 run_tests.py --categories "Deployment Tests" --skip-setup

    - name: Upload Docker test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: docker-test-results
        path: test-results/

  performance-test:
    runs-on: ubuntu-latest
    needs: test

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: 3.9

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r test-requirements.txt

    - name: Run performance tests
      run: |
        python -m pytest tests/performance -v --tb=short --junit-xml=test-results/performance-results.xml -m "not slow"

    - name: Upload performance results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-test-results
        path: test-results/

  deployment-readiness:
    runs-on: ubuntu-latest
    needs: [test, docker-test, performance-test]
    if: always()

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: 3.9

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r test-requirements.txt

    - name: Download all test results
      uses: actions/download-artifact@v3

    - name: Run complete test suite
      run: |
        python3 run_tests.py

    - name: Generate deployment readiness report
      run: |
        echo "# VinylVault Deployment Readiness Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
        if [ -f test-results/test-report.json ]; then
          python3 -c "
          import json
          with open('test-results/test-report.json') as f:
              data = json.load(f)
          summary = data['summary']
          print(f'- **Total Tests**: {summary[\"total_tests\"]}')
          print(f'- **Passed**: {summary[\"total_passed\"]} ({summary[\"total_passed\"]/summary[\"total_tests\"]*100:.1f}%)' if summary['total_tests'] > 0 else '- **Passed**: 0')
          print(f'- **Failed**: {summary[\"total_failed\"]}')
          print(f'- **Skipped**: {summary[\"total_skipped\"]}')
          print('')
          print('## Deployment Status')
          if summary['deployment_ready']:
              print('✅ **READY FOR DEPLOYMENT**')
          else:
              print('❌ **NOT READY FOR DEPLOYMENT**')
          " >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ No test results available" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Upload final test report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: final-test-report
        path: |
          test-results/
          htmlcov/

    - name: Comment PR with test results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          try {
            const testData = JSON.parse(fs.readFileSync('test-results/test-report.json', 'utf8'));
            const summary = testData.summary;
            
            const deploymentStatus = summary.deployment_ready ? '✅ Ready for deployment' : '❌ Not ready for deployment';
            
            const comment = `## 🧪 Test Results
            
            ${deploymentStatus}
            
            - **Total Tests**: ${summary.total_tests}
            - **Passed**: ${summary.total_passed} (${summary.total_tests > 0 ? (summary.total_passed/summary.total_tests*100).toFixed(1) : 0}%)
            - **Failed**: ${summary.total_failed}
            - **Skipped**: ${summary.total_skipped}
            
            ### Test Categories
            ${testData.results.map(r => `- **${r.category}**: ${r.passed}/${r.total} passed (${r.total > 0 ? (r.passed/r.total*100).toFixed(1) : 0}%)`).join('\n')}
            
            📊 [View detailed coverage report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          } catch (error) {
            console.log('Could not read test results:', error);
          }